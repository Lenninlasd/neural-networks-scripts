{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def SSE(y, y_hat):\n",
    "    #sum of the squared errors (SSE)\n",
    "    return 0.5*np.sum((y - y_hat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = np.array([2.3, 4.9])\n",
    "\n",
    "inputs = np.array([\n",
    "    [2,4,5],\n",
    "    [6,7,8]\n",
    "])\n",
    "n_records, n_inputs = inputs.shape\n",
    "n_hidden = 4  # number of hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights\n",
    "We want these to be small such that the input to the sigmoid is in the linear region near 0 and not squashed at the high and low ends. It's also important to initialize them randomly so that they all have different starting values and diverge, breaking symmetry. So, we'll initialize the weights from a normal distribution centered at 0. A good value for the scale is 1/√n where n is the number of input units. This keeps the input to the sigmoid low for increasing numbers of input units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  14.2665527607\n",
      "Train loss:  4.073877638\n",
      "Train loss:  1.62061147507\n",
      "Train loss:  1.42540319315\n",
      "Train loss:  1.33267688656\n",
      "Train loss:  1.23749133537\n",
      "Train loss:  1.1329340063\n",
      "Train loss:  1.02146032001\n",
      "Train loss:  0.897418505767\n",
      "Train loss:  0.762365125298\n",
      "Train loss:  0.622354600346\n",
      "Train loss:  0.487108663416\n",
      "Train loss:  0.366860694159\n",
      "Train loss:  0.267304889849\n",
      "Train loss:  0.189174937881\n",
      "Train loss:  0.130553737406\n",
      "Train loss:  0.0882503510278\n",
      "Train loss:  0.0586821949159\n",
      "Train loss:  0.038525719334\n",
      "Train loss:  0.0250453112499\n",
      "Train loss:  0.0161593999047\n",
      "Train loss:  0.0103658843461\n",
      "Train loss:  0.0066198464816\n",
      "Train loss:  0.00421298657373\n",
      "Train loss:  0.002674046179\n",
      "Train loss:  0.00169372163746\n",
      "Train loss:  0.00107104535341\n",
      "Train loss:  0.000676425263728\n",
      "Train loss:  0.000426773129487\n",
      "Train loss:  0.000269049675339\n",
      "Train loss:  0.000169511292759\n",
      "Train loss:  0.000106746210417\n",
      "Train loss:  6.71952642047e-05\n",
      "Train loss:  4.22855919137e-05\n",
      "Train loss:  2.66036628798e-05\n",
      "Train loss:  1.67343021641e-05\n",
      "Train loss:  1.052466313e-05\n",
      "Train loss:  6.61845902187e-06\n",
      "Train loss:  4.1616394162e-06\n",
      "Train loss:  2.61661268395e-06\n",
      "Train loss:  1.6450860966e-06\n",
      "Train loss:  1.03423057913e-06\n",
      "Train loss:  6.50174470888e-07\n",
      "Train loss:  4.08723500259e-07\n",
      "Train loss:  2.56932549257e-07\n",
      "Train loss:  1.61510430425e-07\n",
      "Train loss:  1.0152561464e-07\n",
      "Train loss:  6.38183557068e-08\n",
      "Train loss:  4.01154412941e-08\n",
      "Train loss:  2.52158929229e-08\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'weights_input_hidden': np.random.normal(scale=1/n_inputs**.5, size=(n_inputs, n_hidden)),\n",
    "    'weights_hidden_output': np.random.normal(scale=1/n_inputs**.5, size=n_hidden)\n",
    "}\n",
    "\n",
    "# Neural Network hyperparameters\n",
    "epochs = 5000\n",
    "learnrate = 0.005\n",
    "\n",
    "last_loss = None\n",
    "\n",
    "\n",
    "# delta_error_hidden = np.dot(delta_error_output, weights['weights_hidden_output']) #* hidden_output(1 - hidden_output)\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w_input_hidden = np.zeros(weights['weights_input_hidden'].shape)\n",
    "    del_w_hidden_output = np.zeros(weights['weights_hidden_output'].shape)\n",
    "\n",
    "    for x, y in zip(inputs, targets):\n",
    "        hidden_output = sigmoid(np.dot(x, weights['weights_input_hidden']))\n",
    "        output = np.dot(hidden_output, weights['weights_hidden_output'])\n",
    "        ## Backward pass ##\n",
    "        delta_error_output = (y - output)\n",
    "\n",
    "        # δh = W * δo * f′(h)\n",
    "        delta_hidden_error = np.dot(delta_error_output, weights['weights_hidden_output']) * hidden_output * (1 - hidden_output)\n",
    "\n",
    "        # TODO: Update the change in weights\n",
    "        del_w_hidden_output += delta_error_output * hidden_output\n",
    "        del_w_input_hidden += delta_hidden_error * x[:, None]\n",
    "    \n",
    "    # Update weights\n",
    "    weights['weights_input_hidden'] += learnrate * del_w_input_hidden / n_records\n",
    "    weights['weights_hidden_output'] += learnrate * del_w_hidden_output / n_records\n",
    "    \n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 50) == 0:\n",
    "        hidden_output = sigmoid(np.dot(inputs, weights['weights_input_hidden']))\n",
    "        out = np.dot(hidden_output, weights['weights_hidden_output'])\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
